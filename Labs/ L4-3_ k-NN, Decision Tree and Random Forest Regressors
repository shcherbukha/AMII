{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1i_vvGvhYnu-spG83YBj35ik_z_PdME7C","timestamp":1667970702817},{"file_id":"1YkwHIaighujq7H9SJzTTLwdy1OqXwUd1","timestamp":1616785644077},{"file_id":"1rjgAdwOrbr-c_nNpk8jn-hslMt5XvjXZ","timestamp":1616166499739},{"file_id":"1BV-XefxPXDulctYDH73s5ysd0kHkCJ3R","timestamp":1607066531951}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["###Disclaimer\n","The information contained in this notebook and any accompanying files are proprietary and is confidential to the participants of the Machine Learning Technician program and should not be copied, distributed or reproduced in whole or in part, nor passed to any third party without written permission from the Alberta Machine Intelligence Institute, Amii."],"metadata":{"id":"Oets4bBWHNQ9"}},{"cell_type":"markdown","metadata":{"id":"Roa48z8A5GBd"},"source":["#L4-3: *k*-NN, Decision Tree and Random Forest Regressors"]},{"cell_type":"markdown","metadata":{"id":"xpccvJlm8N-f"},"source":["In this notebook, we will try a few more regression methods as well as review the main steps involved in the ML process."]},{"cell_type":"markdown","metadata":{"id":"Xu-j6luR8WGm"},"source":["First, let's load some packages:"]},{"cell_type":"code","metadata":{"id":"G2JcP0GDCnr_"},"source":["import numpy as np\n","import pandas as pd\n","import plotly.express as px"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8oQb-UmPVUgB"},"source":["We will be using the Automobile dataset from UCI datasets repository, which is assessing riskiness of insuring a number of different cars:\n","\n","https://archive.ics.uci.edu/ml/datasets/Automobile\n","\n","The target variable is called 'symboling' and whose values are in $\\{-3,-2,-1,0,+1,+2,+3\\}$. A symboling of $-3$ indicates a very safe vehicle (in terms of insurance riskiness) whereas a value $+3$ indicates a very risky insurance.\n","\n","Features include specifications about the car as well as the price, which the insurance quota is based on. If a car is likely to induce higher risk cost as compared to its price tag level, it is considered risky. The average loss per vehicle in a year is recorded in the **normalized_losses** feature.\n","\n","Let's load the dataset and put it in a DataFrame:"]},{"cell_type":"code","metadata":{"id":"Efms_5gkDiK3"},"source":["url = \"https://archive.ics.uci.edu/ml/machine-learning-databases\" + \\\n","      \"/autos/imports-85.data\"\n","column_names = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \\\n","                \"aspiration\", \"num_of_doors\", \"body_style\", \"drive_wheels\", \\\n","                \"engine_location\", \"wheel_base\", \"length\", \"width\", \"height\", \\\n","                \"curb_weight\", \"engine_type\", \"num_of_cylinders\", \\\n","                \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \\\n","                \"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\", \\\n","                \"highway_mpg\", \"price\"]\n","label_name = column_names[0]\n","feature_names = column_names[1:]\n","df = pd.read_csv(url, names=column_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cIKAZKrI-wm1"},"source":["## EDA"]},{"cell_type":"markdown","metadata":{"id":"aj6NvLxK-qJa"},"source":["The first step is doing EDA. We start by inspecting the data in table format, the we inspect statistics of features and visualiztion:"]},{"cell_type":"code","metadata":{"id":"b7PLT_2iDrJe"},"source":["display(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zzqjPJtMEhbW"},"source":["display(df.describe())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMxMnCx6Eoo8"},"source":["fig = px.scatter_matrix(df, dimensions=column_names, color=label_name)\n","\n","fig.update_layout(width=len(df.columns) * 200,\n","                 height=len(df.columns) * 200,\n","                 margin=dict(l=0, r=0, t=0, b=0))\n","\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"adNXFPYEgJTg"},"source":["for feature in column_names:\n","  fig = px.histogram(df, x=feature, color=label_name, marginal=\"box\")\n","  fig.update_layout(height=300, margin=dict(l=0, r=0, t=0, b=0))\n","  fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CKhVyxCQ-_Ay"},"source":["## Data Cleaning"]},{"cell_type":"markdown","metadata":{"id":"XbgxQlGt_AsC"},"source":["We clean the data by converting numerical column into actual numbers, converting the features into their appropriate data type, followed by checking for duplicate datapoints:"]},{"cell_type":"code","metadata":{"id":"I-jyJNvditBK"},"source":["numerical_columns = [\"symboling\", \"normalized_losses\", \"wheel_base\", \"length\", \\\n","                     \"width\", \"height\", \"curb_weight\", \"engine_size\", \"bore\", \\\n","                     \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\", \\\n","                     \"city_mpg\", \"highway_mpg\", \"price\"]\n","integer_columns = [\"symboling\", \"num_of_doors\", \"num_of_cylinders\"]\n","float_columns = [\"normalized_losses\", \"wheel_base\", \"length\", \"width\", \\\n","                 \"height\", \"curb_weight\", \"engine_size\", \"bore\", \"stroke\", \\\n","                 \"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\", \\\n","                 \"highway_mpg\", \"price\"]\n","categorical_columns = [\"make\", \"fuel_type\", \"aspiration\", \"body_style\", \\\n","                       \"drive_wheels\", \"engine_location\", \"engine_type\", \\\n","                       \"fuel_system\"]\n","binary_categorical_columns = [\"fuel_type\", \"aspiration\", \"engine_location\"]\n","non_binary_categorical_columns = [\"make\", \"body_style\", \"drive_wheels\", \\\n","                                  \"engine_type\", \"fuel_system\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8a_ulyEzhg1C"},"source":["display(df.dtypes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTVO2BVYkUEj"},"source":["df[\"num_of_doors\"].replace(\"two\",  2, inplace=True)\n","df[\"num_of_doors\"].replace(\"four\", 4, inplace=True)\n","\n","df[\"num_of_cylinders\"].replace(\"two\",     2, inplace=True)\n","df[\"num_of_cylinders\"].replace(\"three\",   3, inplace=True)\n","df[\"num_of_cylinders\"].replace(\"four\",    4, inplace=True)\n","df[\"num_of_cylinders\"].replace(\"five\",     5, inplace=True)\n","df[\"num_of_cylinders\"].replace(\"six\",     6, inplace=True)\n","df[\"num_of_cylinders\"].replace(\"eight\",   8, inplace=True)\n","df[\"num_of_cylinders\"].replace(\"twelve\", 12, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJZp4PN2hrpt"},"source":["df[\"bore\"]              = pd.to_numeric(df[\"bore\"],\\\n","                                        errors='coerce')\n","df[\"stroke\"]            = pd.to_numeric(df[\"stroke\"], \\\n","                                        errors='coerce')\n","df[\"normalized_losses\"] = pd.to_numeric(df[\"normalized_losses\"], \\\n","                                        errors='coerce')\n","df[\"horsepower\"]        = pd.to_numeric(df[\"horsepower\"], \\\n","                                        errors='coerce')\n","df[\"peak_rpm\"]          = pd.to_numeric(df[\"peak_rpm\"],\\\n","                                        errors='coerce')\n","df[\"price\"]             = pd.to_numeric(df[\"price\"], \\\n","                                        errors='coerce')\n","df[\"num_of_doors\"]      = pd.to_numeric(df[\"num_of_doors\"], \\\n","                                        errors='coerce', \\\n","                                        downcast='unsigned')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVvIyl3qo76d"},"source":["for feature in categorical_columns:\n","  df[feature] = df[feature].astype('category')  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBbz67oYoif1"},"source":["display(df.dtypes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPAwjc8Epbbw"},"source":["display(df[df.duplicated()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKh8RhDq_5bm"},"source":["## EDA, Run 2"]},{"cell_type":"markdown","metadata":{"id":"svQMRBHd_0Xa"},"source":["Let's do another round of visualizations:"]},{"cell_type":"code","metadata":{"id":"JLp_NeWLpnWF"},"source":["fig = px.scatter_matrix(df, dimensions=column_names, color=label_name)\n","\n","fig.update_layout(width=len(df.columns) * 200,\n","                 height=len(df.columns) * 200,\n","                 margin=dict(l=0, r=0, t=0, b=0))\n","\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vx8bLdsLqFCi"},"source":["for feature in column_names:\n","  fig = px.histogram(df, x=feature, color=label_name, marginal=\"box\")\n","  fig.update_layout(height=300, margin=dict(l=0, r=0, t=0, b=0))\n","  fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QeXW6uCn5C2f"},"source":["And finally, let's inspect the data in table format:"]},{"cell_type":"code","metadata":{"id":"77ycYxstAYly"},"source":["display(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W511eXVDAFg1"},"source":["## Data Cleaning, Run 2"]},{"cell_type":"markdown","metadata":{"id":"0y6Vtj55ANGB"},"source":["Now, let's convert every feature into numbers:"]},{"cell_type":"code","metadata":{"id":"_YoohgUKq-sM"},"source":["for feature in non_binary_categorical_columns:\n","  df = pd.concat([df, pd.get_dummies(df[feature], \n","                                     prefix=feature)], \\\n","                 axis=1).drop([feature], axis=1)\n","for feature in binary_categorical_columns:\n","  df = pd.concat([df, pd.get_dummies(df[feature], \\\n","                                     prefix=feature, \\\n","                                     drop_first=True)], \\\n","                 axis=1).drop([feature], axis=1)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTjsj6jRwFxq"},"source":["display(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g43jaC5lAWkc"},"source":["...and let's fix a bit of typos and inconsistencies:"]},{"cell_type":"code","metadata":{"id":"rJGvnNw6w1hL"},"source":["df = df.rename(columns={\"make_alfa-romero\": \"make_alfa_romeo\", \\\n","                        \"make_mercedes-benz\": \"make_mercedes_benz\"})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fP6YZTFPAo0e"},"source":["Let's check the statistics once more:"]},{"cell_type":"code","metadata":{"id":"qCpMtfqgqRU0"},"source":["display(df.describe())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8I_-OMyCAuJg"},"source":["Now we can get to handling missing values:"]},{"cell_type":"code","metadata":{"id":"5Cq9-Hj9Nej-"},"source":["columns_with_na = \\\n","  list(df.columns[df.describe().loc['count', :] < len(df.index)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ky9KycRCF3gp"},"source":["display(columns_with_na)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cuARSenZAywo"},"source":["These columns (above) had missing value in them. Let's add some new columns which indicate what values in those columns were missing (missingness features):"]},{"cell_type":"code","metadata":{"id":"k428NIlPqY0V"},"source":["for feature in columns_with_na:\n","  df[feature + \"_missing\"] = df[feature].isnull().astype(\"uint8\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7J1FNozOBLtF"},"source":["...and let's reorder our columns before we continue. We will get the column names first and use that to order our columns:"]},{"cell_type":"code","metadata":{"id":"rjYb42v_Dwby"},"source":["df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zY2pyyqQykmH"},"source":["df = df[[\"normalized_losses\", \"normalized_losses_missing\", \"num_of_doors\", \\\n","         \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\", \\\n","         \"num_of_cylinders\", \"engine_size\", \"bore\", \"stroke\", \\\n","         \"compression_ratio\", \"horsepower\", \"num_of_doors_missing\", \\\n","         \"bore_missing\", \"stroke_missing\", \"horsepower_missing\", \"peak_rpm\", \\\n","         \"peak_rpm_missing\", \"city_mpg\", \"highway_mpg\", \"price\", \\\n","         \"price_missing\", \"make_alfa_romeo\", \"make_audi\", \"make_bmw\", \\\n","         \"make_chevrolet\", \"make_dodge\", \"make_honda\", \"make_isuzu\", \\\n","         \"make_jaguar\", \"make_mazda\", \"make_mercedes_benz\", \"make_mercury\", \\\n","         \"make_mitsubishi\", \"make_nissan\", \"make_peugot\", \"make_plymouth\", \\\n","         \"make_porsche\", \"make_renault\", \"make_saab\", \"make_subaru\", \\\n","         \"make_toyota\", \"make_volkswagen\", \"make_volvo\", \"fuel_type_gas\", \\\n","         \"aspiration_turbo\", \"body_style_convertible\", \"body_style_hardtop\", \\\n","         \"body_style_hatchback\", \"body_style_sedan\", \"body_style_wagon\", \\\n","         \"drive_wheels_4wd\", \"drive_wheels_fwd\", \"drive_wheels_rwd\", \\\n","         \"engine_location_rear\", \"engine_type_dohc\", \"engine_type_dohcv\", \\\n","         \"engine_type_l\", \"engine_type_ohc\", \"engine_type_ohcf\", \\\n","         \"engine_type_ohcv\", \"engine_type_rotor\", \"fuel_system_1bbl\", \\\n","         \"fuel_system_2bbl\", \"fuel_system_4bbl\", \"fuel_system_idi\", \\\n","         \"fuel_system_mfi\", \"fuel_system_mpfi\", \"fuel_system_spdi\", \\\n","         \"fuel_system_spfi\", \"symboling\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nYY5tX4YBUSk"},"source":["This is the reordered DataFrame:"]},{"cell_type":"code","metadata":{"id":"LVWb1BeuNPx2"},"source":["display(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KtCCt8CgBYvC"},"source":["Now, let's impute the missing values. But before we do that let's do data splitting. Best practice is to do data splitting before some kinds of cleaning (like imputing missing values as well as normalization) so we find the parameters for those cleaning operations using only the training data and that gives us a more unbiased estimate:"]},{"cell_type":"code","metadata":{"id":"tPVYX8svHB5w"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCicryDzG9WW"},"source":["df_train_validation, df_test = \\\n","  train_test_split(df, test_size=0.2, random_state=42)\n","df_train, df_validation = \\\n","  train_test_split(df_train_validation, test_size=0.25, random_state=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N7yHj2oXG8iU"},"source":[" Now, we can get to handling missing values. This is not time-series data, so we do normal imputation. However, we will do a more advanced method of imputation: we will use a regressor, a $k$-NN regressor to be precise, to fill in the missing values. We will use one $k$-NN regressor model for each feature with missing values and the input is all the features which don't have missing values:"]},{"cell_type":"code","metadata":{"id":"1tsHnEluQp2_"},"source":["from  sklearn.neighbors import KNeighborsRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"McAF1Y-_lVvp"},"source":["https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html"]},{"cell_type":"code","metadata":{"id":"sgZakJOtydEH"},"source":["bad_columns = columns_with_na + [label_name]\n","for feature in columns_with_na: # We have made sure that the label \n","                                # does not have missing values\n","  print(feature)\n","  is_missing_train = df_train[feature].isnull()\n","  knn_reg_imputer = KNeighborsRegressor(n_neighbors=5)\n","  X_not_missing_train = \\\n","    df_train[~is_missing_train].drop(bad_columns, axis=1).values\n","  y_not_missing_train = \\\n","    df_train[~is_missing_train][feature].values\n","  knn_reg_imputer.fit(X_not_missing_train, y_not_missing_train)\n","\n","  is_missing_validation = df_validation[feature].isnull()\n","  is_missing_test = df_test[feature].isnull()\n","  X_missing_train = \\\n","    df_train[is_missing_train].drop(bad_columns, axis=1).values\n","  X_missing_validation = \\\n","    df_validation[is_missing_validation].drop(bad_columns, axis=1).values\n","  X_missing_test = \\\n","    df_test[is_missing_test].drop(bad_columns, axis=1).values \n","  if X_missing_train.shape[0] > 0:\n","    yhat_missing_train = knn_reg_imputer.predict(X_missing_train)\n","    df_train.loc[is_missing_train, feature] = yhat_missing_train\n","  if X_missing_validation.shape[0] > 0:\n","    yhat_missing_validation = knn_reg_imputer.predict(X_missing_validation)\n","    df_validation.loc[is_missing_validation, feature] = yhat_missing_validation\n","  if X_missing_test.shape[0] > 0:\n","    yhat_missing_test = knn_reg_imputer.predict(X_missing_test)\n","    df_test.loc[is_missing_test, feature] = yhat_missing_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fRUnk8QRCCHd"},"source":["Now, we can check if we have any missing values left:"]},{"cell_type":"code","metadata":{"id":"EZ4pDg3RPmSx"},"source":["display(df_train.columns[df_train.describe().loc['count', :] < \\\n","                         len(df_train.index)])\n","display(df_validation.columns[df_validation.describe().loc['count', :] < \\\n","                              len(df_validation.index)])\n","display(df_test.columns[df_test.describe().loc['count', :] < \\\n","                        len(df_test.index)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z6LZTosTCGF_"},"source":["..and we don't, as expected. Let's take another look at our dataset after imputation of missing values:"]},{"cell_type":"code","metadata":{"id":"Lla3KRc5SySx"},"source":["display(df_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_L9ssMJoHSH"},"source":["display(df_validation)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4d10QzUoJrl"},"source":["display(df_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SZ3vv4RPM5lJ"},"source":["Finally, we normalize our data:"]},{"cell_type":"code","metadata":{"id":"vdIgeXdXM8kO"},"source":["from sklearn.preprocessing import MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8nBedVDRM8z4"},"source":["scalable_features = ['normalized_losses', 'num_of_doors', 'wheel_base', \\\n","                     'length', 'width', 'height', 'curb_weight', \\\n","                     'num_of_cylinders', 'engine_size', 'bore', 'stroke', \\\n","                     'compression_ratio', 'horsepower', 'peak_rpm', \\\n","                     'city_mpg', 'highway_mpg', 'price', 'fuel_type_gas', \\\n","                     'aspiration_turbo']\n","min_max_scaler = MinMaxScaler()\n","min_max_scaler.fit(df_train.loc[:, scalable_features])\n","df_train.loc[:, scalable_features] = \\\n","  min_max_scaler.transform(df_train.loc[:, scalable_features])\n","df_validation.loc[:, scalable_features] = \\\n","  min_max_scaler.transform(df_validation.loc[:, scalable_features])\n","df_test.loc[:, scalable_features] = \\\n","  min_max_scaler.transform(df_test.loc[:, scalable_features])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRvOo2haZ_VS"},"source":["display(df_train.describe())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"So1W3tLwoDIm"},"source":["display(df_validation.describe())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgjdbuwvoDLX"},"source":["display(df_test.describe())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwKzR9FWO1gZ"},"source":["m_train, n = df_train.shape\n","m_validation = df_validation.shape[0]\n","m_test = df_validation.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DgL26_Q1CYn0"},"source":["## Building ML models"]},{"cell_type":"markdown","metadata":{"id":"MOX04lgBDNJz"},"source":["Now, we build our regression models. Let's load some regressor from scikit-learn and apply them. We specifically apply Lasso, $k$-NN regressor and DT Regressors. We use the $R^2$ score for validation. Remember $R^2$ is a score and the best score is the biggest score:"]},{"cell_type":"code","metadata":{"id":"5kzREYvfXyrm"},"source":["from sklearn.linear_model import Lasso\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import r2_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W6cmbflmlbxr"},"source":["https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"]},{"cell_type":"code","metadata":{"id":"1QAuSFD6ewCt"},"source":["X_train = df_train.drop(label_name, axis=1)\n","y_train = df_train[label_name]\n","X_validation = df_validation.drop(label_name, axis=1)\n","y_validation = df_validation[label_name]\n","X_test = df_test.drop(label_name, axis=1)\n","y_test = df_test[label_name]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEOCFx66X9Tb"},"source":["lasso_regressor = Lasso()\n","lasso_regressor.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qk4_xiInYEPu"},"source":["yhat_validation = lasso_regressor.predict(X_validation)\n","\n","display(r2_score(y_validation, yhat_validation))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5K8TKCPXg_7"},"source":["knn_regressor = KNeighborsRegressor()\n","knn_regressor.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmHvetcMXu6x"},"source":["yhat_validation = knn_regressor.predict(X_validation)\n","\n","display(r2_score(y_validation, yhat_validation))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sy2ne8VYTKU"},"source":["dt_regressor = DecisionTreeRegressor()\n","dt_regressor.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnqTWoJ8YTMk"},"source":["yhat_validation = dt_regressor.predict(X_validation)\n","\n","display(r2_score(y_validation, yhat_validation))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPJTRkt7D4PG"},"source":["We can also do a grid-search for hyperparameters in the validation loop and here we do that for the regularization coefficient for lasso (remember that an efficient regularization coefficient search should be done on a logarithmic rather than a linear grid):"]},{"cell_type":"code","metadata":{"id":"TKtOyL73YmMB"},"source":["best_r2_score = -np.infty\n","best_alpha = np.nan\n","for alpha in np.logspace(-3, 0, 50):\n","  lasso_regressor = Lasso(alpha=alpha)\n","  lasso_regressor.fit(X_train, y_train)\n","  yhat_validation = lasso_regressor.predict(X_validation)\n","  this_r2_score = r2_score(y_validation, yhat_validation)\n","  \n","  print(\"Regularization coefficient:\", alpha)\n","  yhat_train = lasso_regressor.predict(X_train)\n","  print(\"\\tR2 score on training data is\", r2_score(y_train, yhat_train))\n","  print(\"\\tR2 score on validation data is\", this_r2_score)\n","  if  this_r2_score > best_r2_score:\n","    best_r2_score = this_r2_score\n","    best_alpha = alpha\n","print(\"Best alpha found is\", best_alpha)\n","print(\"Best r2 score for this alpha is\", best_r2_score)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"92JkVgcnEO3F"},"source":["Now, we can train an ML model using the best hyperparameter found:"]},{"cell_type":"code","metadata":{"id":"XxO9Ha0dKQB0"},"source":["lasso_regressor = Lasso(alpha=best_alpha)\n","lasso_regressor.fit(X_train, y_train)\n","\n","yhat_test = lasso_regressor.predict(X_test)\n","print(\"R2 score on test data for best alpha is\", r2_score(y_test, yhat_test))\n","\n","display(lasso_regressor.coef_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2QuQgTFiE92X"},"source":["We can see many features are assigned a weight of zero because lasso induces sparsity. Let's see what features were informative:"]},{"cell_type":"code","metadata":{"id":"VQimqbgzaZPe"},"source":["# active_features_index = np.where(lasso_regressor.coef_ != 0)[0]\n","active_features_index = np.where(np.abs(lasso_regressor.coef_) > 1e-5)[0]\n","display(list(df.columns[active_features_index]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUxFbbp-lTEw"},"source":["feature_weights = pd.DataFrame(df.columns[:-1], columns=['feature_name'])\n","feature_weights['weight'] = lasso_regressor.coef_\n","fig = px.bar(feature_weights, x='feature_name', y='weight', \\\n","            color='weight', color_continuous_scale='Temps')\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-GaGEg_gu0Vu"},"source":["## Feature Selection with Lasso"]},{"cell_type":"code","metadata":{"id":"jjAflrcuv3dG"},"source":["alpha = 1e-4\n","num_non_zero_weights = n\n","while num_non_zero_weights > 2:\n","  print(\"Regularization coefficient:\", alpha)\n","  lasso_regressor = Lasso(alpha=alpha)\n","  lasso_regressor.fit(X_train, y_train)\n","  num_non_zero_weights = (lasso_regressor.coef_ != 0).sum()\n","  print(\"Number of non-zero weights is\", num_non_zero_weights)\n","  alpha *= 1.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U0yNYUvzyjrM"},"source":["np.where(lasso_regressor.coef_ != 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBtFSqCIyqy_"},"source":["top_2_features = np.where(lasso_regressor.coef_ != 0)[0]\n","display(top_2_features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILmBFIZKytki"},"source":["df.columns[top_2_features]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPWhzoyMz53F"},"source":["## k-NN Regression Visualization"]},{"cell_type":"code","metadata":{"id":"wR2-uKo0z6JI"},"source":["import plotly.graph_objects as go"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_3Rk2G30aK7"},"source":["X_train_f = df_train[float_columns]\n","y_train_f = y_train\n","\n","alpha = 1e-4\n","num_non_zero_weights = X_train.shape[1]\n","while num_non_zero_weights > 2:\n","  print(\"Regularization coefficient:\", alpha)\n","  lasso_regressor = Lasso(alpha=alpha)\n","  lasso_regressor.fit(X_train_f, y_train_f)\n","  num_non_zero_weights = (lasso_regressor.coef_ != 0).sum()\n","  print(\"Number of non-zero weights is\", num_non_zero_weights)\n","  alpha *= 1.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZQsNrKu1FNt"},"source":["top_2_features = np.where(lasso_regressor.coef_ != 0)[0]\n","\n","top_2_float_features_names = np.array(float_columns)[top_2_features]\n","display(top_2_float_features_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"45PdGCgJwGZ1"},"source":["X2_train = df_train[top_2_float_features_names]\n","y2_train = y_train\n","X2_test = df_test[top_2_float_features_names]\n","y2_test = y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MFqmNCLEwLwL"},"source":["x_mins = np.minimum(np.min(X2_train, axis=0), np.min(X2_test, axis=0))\n","x_maxs = np.maximum(np.max(X2_train, axis=0), np.max(X2_test, axis=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwIYi00KwOBm"},"source":["x0_vis_range = np.arange(x_mins[0] - 0.1, x_maxs[0] + 0.1, 0.005)\n","x1_vis_range = np.arange(x_mins[1] - 0.1, x_maxs[1] + 0.1, 0.005)\n","XX0_vis, XX1_vis = np.meshgrid(x0_vis_range, x1_vis_range)\n","X_vis = np.c_[XX0_vis.flatten(), XX1_vis.flatten()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Y46hORMwJYH"},"source":["knn_regressor = KNeighborsRegressor(n_neighbors=7)\n","knn_regressor.fit(X2_train, y2_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hXEfyN3zvWJU"},"source":["yhat_vis = knn_regressor.predict(X_vis)\n","\n","YYhat_vis = yhat_vis.reshape(XX0_vis.shape)\n","\n","yhat_test = knn_regressor.predict(X2_test)\n","\n","fig = go.Figure()\n","fig.add_trace(go.Surface(x=x0_vis_range,\n","                         y=x1_vis_range,\n","                         z=YYhat_vis,\n","                         colorscale='Viridis'))\n","fig.add_trace(go.Scatter3d(x=X2_train.values[:, 0], \n","                          y=X2_train.values[:, 1],\n","                          z=y2_train.values,\n","                          mode='markers',\n","                          marker=dict(color=y2_train.values, \n","                                      colorscale='Viridis',\n","                                      size=6)))\n","fig.add_trace(go.Scatter3d(x=X2_test.values[:, 0], \n","                          y=X2_test.values[:, 1],\n","                          z=y2_test.values,\n","                          mode='markers',\n","                          marker=dict(size=6, color='black')))\n","\n","fig.update_layout(scene_aspectratio=dict(x=2, y=2, z=1))\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4Os9_n9_rOs"},"source":["knn_regressor = KNeighborsRegressor(weights='distance', n_neighbors=7)\n","knn_regressor.fit(X2_train, y2_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_448Fvz_T2d"},"source":["yhat_vis = knn_regressor.predict(X_vis)\n","\n","YYhat_vis = yhat_vis.reshape(XX0_vis.shape)\n","\n","yhat_test = knn_regressor.predict(X2_test)\n","\n","fig = go.Figure()\n","fig.add_trace(go.Surface(x=x0_vis_range,\n","                         y=x1_vis_range,\n","                         z=YYhat_vis,\n","                         colorscale='Viridis'))\n","fig.add_trace(go.Scatter3d(x=X2_train.values[:, 0], \n","                          y=X2_train.values[:, 1],\n","                          z=y2_train.values,\n","                          mode='markers',\n","                          marker=dict(color=y2_train.values, \n","                                      colorscale='Viridis',\n","                                      size=6)))\n","fig.add_trace(go.Scatter3d(x=X2_test.values[:, 0], \n","                          y=X2_test.values[:, 1],\n","                          z=y2_test.values,\n","                          mode='markers',\n","                          marker=dict(size=6, color='black')))\n","\n","fig.update_layout(scene_aspectratio=dict(x=2, y=2, z=1))\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"afGqnULbB1jZ"},"source":["## DT Regressor"]},{"cell_type":"code","metadata":{"id":"vKsRhjsvB1sU"},"source":["dt_regressor = DecisionTreeRegressor()\n","dt_regressor.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uv24P75qCGRh"},"source":["import graphviz\n","from sklearn.tree import export_graphviz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qDCXI8FPCNzu"},"source":["dot_data = export_graphviz(dt_regressor,\n","                           out_file=None, \n","                           filled=True,\n","                           rounded=True,  \n","                           rotate=True)  \n","\n","display(graphviz.Source(dot_data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"92c74RuOAwAS"},"source":["## Grid Search Review"]},{"cell_type":"code","metadata":{"id":"6Y4HNA4VAykx"},"source":["from sklearn.model_selection import GridSearchCV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHQ3U_tSAzbR"},"source":["lasso_search = GridSearchCV(estimator=Lasso(), \\\n","                            cv=5, \\\n","                            param_grid=dict(alpha=np.logspace(-3, 0, 50)), \\\n","                            scoring='r2')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fo-sUyt4A308"},"source":["lasso_search.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F1N-0QUpA6o4"},"source":["lasso_search.best_estimator_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mx8ojmY0RLHX"},"source":["## Variance of DT and Random Forests"]},{"cell_type":"code","metadata":{"id":"lI5I4NGTRLO5"},"source":["from sklearn.utils import resample"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CLH25JttlsBr"},"source":["https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"]},{"cell_type":"code","metadata":{"id":"rZuWkNvARSUt"},"source":["def estimate_model_bias_variance(estimator, X_train, y_train, X_test, y_test, \\\n","                                 num_trials, resample_size):\n","\n","  yhat_test_trial = np.tile(y_test[:, None], (1, num_trials))\n","\n","  for i in range(num_trials):\n","    X_train_trial, y_train_trial = \\\n","      resample(X_train, y_train, replace=False, n_samples=resample_size)\n","    estimator.fit(X_train_trial, y_train_trial)\n","    yhat_test_trial[:, i] = estimator.predict(X_test)\n","\n","  prediction_variances = yhat_test_trial.std(axis=1)\n","  model_variance_estimate = prediction_variances.mean()\n","  model_variance_std = prediction_variances.std()\n","  prediction_mae = np.abs(yhat_test_trial - y_test[:, None]).mean(axis=1)\n","  model_bias_estimate = prediction_mae.mean()\n","  model_bias_std = prediction_mae.std()\n","\n","  return (model_bias_estimate, model_variance_estimate, \\\n","          model_bias_std, model_variance_std)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRbPRmrvhdLJ"},"source":["num_trials = 100\n","resample_size = m_train // 2\n","bias, variance, bstd, sstd = estimate_model_bias_variance(dt_regressor, X_train, y_train, \\\n","                                              X_test, y_test, \\\n","                                              num_trials, resample_size)\n","\n","print(\"bias:\", bias, \"+/-\", bstd)\n","print(\"variance:\", variance, \"+/-\", sstd)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xWB3l1YEjvZ9"},"source":["from sklearn.ensemble import RandomForestRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OTJoYKb6VafB"},"source":["https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"]},{"cell_type":"code","metadata":{"id":"cwy9tozOjyPB"},"source":["rforest_regressor = RandomForestRegressor()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wInFrBKLjDg4"},"source":["bias, variance, bstd, sstd = estimate_model_bias_variance(rforest_regressor, X_train, y_train, \\\n","                                              X_test, y_test, \\\n","                                              num_trials, resample_size)\n","\n","print(\"bias:\", bias, \"+/-\", bstd)\n","print(\"variance:\", variance, \"+/-\", sstd)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4HrPJqC7a3AW"},"source":["That's all Folks!"]}]}